{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../results_all/app_bootstrap_vm/\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_1.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_10.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_11.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_12.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_13.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_14.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_15.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_16.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_17.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_18.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_19.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_2.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_20.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_21.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_22.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_23.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_24.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_25.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_26.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_27.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_28.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_29.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_3.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_30.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_31.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_32.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_33.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_34.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_35.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_36.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_37.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_38.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_39.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_4.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_40.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_41.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_42.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_43.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_44.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_45.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_46.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_47.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_48.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_49.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_5.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_50.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_51.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_52.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_53.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_54.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_55.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_56.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_57.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_58.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_59.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_6.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_60.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_61.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_62.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_63.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_64.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_65.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_66.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_67.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_68.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_69.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_7.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_8.csv\n",
      "Paring file ../../results_all/app_bootstrap_vm\\app_bootstrap_vm_9.csv\n",
      "Parsing complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "\n",
    "\n",
    "folder = \"../../results_all/app_bootstrap_vm/\"\n",
    "resultfile = \"../../results_aggr/app_bootstrap_vm.csv\"\n",
    "\n",
    "insertJump=3\n",
    "simpleQueryJump=1\n",
    "groupQueryJump=1\n",
    "\n",
    "slidingAvg=10\n",
    "insertTrend=3\n",
    "simpleQueryTrend=1\n",
    "groupQueryTrend=1\n",
    "print(folder)\n",
    "\n",
    "\n",
    "all_files = glob.glob(folder + \"/*\")\n",
    "rows = []\n",
    "\n",
    "for file in all_files:\n",
    "    print(f\"Paring file {file}\")\n",
    "\n",
    "    values = pd.read_csv(file)\n",
    "\n",
    "    for index, row in values.iterrows():\n",
    "        rows.append({\n",
    "            \"commit\":row[\"commit\"],\n",
    "            \"type\": row[\"type\"],\n",
    "            \"min\": row[\"min\"],\n",
    "            \"med\": row[\"med\"],\n",
    "            \"max\": row[\"max\"]\n",
    "        })\n",
    "\n",
    "print(f\"Parsing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create dataframe ...\n",
      "Detect performance changes ...\n",
      "Found potential down jump at commit 29 for type inserts.\n",
      "Found definite up trend at commit 64 for type inserts.\n",
      "Found definite up trend at commit 65 for type inserts.\n",
      "Found definite up trend at commit 66 for type inserts.\n",
      "Found definite up trend at commit 67 for type inserts.\n",
      "Found definite up trend at commit 68 for type inserts.\n",
      "Found potential up jump at commit 9 for type simple queries.\n",
      "Found potential up trend at commit 9 for type simple queries.\n",
      "Found potential down jump at commit 10 for type simple queries.\n",
      "Found potential up trend at commit 10 for type simple queries.\n",
      "Found definite down jump at commit 11 for type simple queries.\n",
      "Found potential down trend at commit 13 for type simple queries.\n",
      "Found definite down trend at commit 14 for type simple queries.\n",
      "Found definite down trend at commit 16 for type simple queries.\n",
      "Found definite down trend at commit 17 for type simple queries.\n",
      "Found potential down jump at commit 59 for type simple queries.\n",
      "Found definite down trend at commit 59 for type simple queries.\n",
      "Found potential down jump at commit 10 for type group-by queries.\n",
      "Found definite down trend at commit 10 for type group-by queries.\n",
      "Found potential up jump at commit 11 for type group-by queries.\n",
      "Found definite down trend at commit 11 for type group-by queries.\n",
      "Found definite down trend at commit 12 for type group-by queries.\n",
      "Found definite down trend at commit 13 for type group-by queries.\n",
      "Found definite down trend at commit 14 for type group-by queries.\n",
      "Found definite down trend at commit 15 for type group-by queries.\n",
      "Found definite down trend at commit 16 for type group-by queries.\n",
      "Found definite down trend at commit 17 for type group-by queries.\n",
      "Found definite down trend at commit 18 for type group-by queries.\n",
      "Found definite down trend at commit 19 for type group-by queries.\n",
      "Found potential up jump at commit 20 for type group-by queries.\n",
      "Found definite up trend at commit 20 for type group-by queries.\n",
      "Found definite up trend at commit 21 for type group-by queries.\n",
      "Found definite up trend at commit 22 for type group-by queries.\n",
      "Found definite up trend at commit 23 for type group-by queries.\n",
      "Found potential down jump at commit 43 for type group-by queries.\n",
      "Found potential up jump at commit 49 for type group-by queries.\n",
      "Found potential down jump at commit 59 for type group-by queries.\n",
      "Found potential down trend at commit 59 for type group-by queries.\n",
      "Found potential down trend at commit 60 for type group-by queries.\n",
      "Found definite down trend at commit 61 for type group-by queries.\n",
      "Found definite down trend at commit 64 for type group-by queries.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ee3812a45516>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_measurements.sort_values(by=[\"commit\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Create dataframe ...\")\n",
    "df_values = pd.DataFrame(rows)\n",
    "df_values.sort_values(by=[\"commit\"], inplace=True)\n",
    "\n",
    "print(f\"Detect performance changes ...\")\n",
    "rows = []\n",
    "\n",
    "for type in df_values.type.unique():\n",
    "    df_measurements = df_values.loc[(df_values['type'].str.startswith(type, na=False))]\n",
    "    df_measurements.sort_values(by=[\"commit\"], inplace=True)\n",
    "\n",
    "    jumpThreshold=-1\n",
    "    trendThreshold=-1\n",
    "    if (type == \"inserts\"):\n",
    "        jumpThreshold=insertJump\n",
    "        trendThreshold=insertTrend\n",
    "    elif (type == \"simple queries\"):\n",
    "        jumpThreshold=simpleQueryJump\n",
    "        trendThreshold=simpleQueryTrend\n",
    "    elif (type == \"group-by queries\"):\n",
    "        jumpThreshold=groupQueryJump\n",
    "        trendThreshold=groupQueryTrend\n",
    "\n",
    "    assert jumpThreshold > 0\n",
    "    assert  trendThreshold > 0\n",
    "\n",
    "    lastValues = []\n",
    "\n",
    "    for index, row in df_measurements.iterrows():\n",
    "        lastValues.append({\n",
    "            \"commit\":row[\"commit\"],\n",
    "            \"min\": row[\"min\"],\n",
    "            \"med\": row[\"med\"],\n",
    "            \"max\": row[\"max\"],\n",
    "        })\n",
    "\n",
    "        # Jump detection\n",
    "        jump = \"\"\n",
    "        if (len(lastValues) > 1):\n",
    "            currVal = lastValues[len(lastValues)-1]['med']\n",
    "            prevVal = lastValues[len(lastValues)-2]['med']\n",
    "            diff = currVal - prevVal\n",
    "            #print(f\"diff is {diff}. {prevVal} -> {currVal}\")\n",
    "            if (diff > jumpThreshold):\n",
    "                jump = \"potential up\"\n",
    "            if ((-1 * diff) > jumpThreshold):\n",
    "                jump = \"potential down\"\n",
    "            if (jump != \"\"):\n",
    "                # check CIs\n",
    "                currMin = lastValues[len(lastValues)-1]['min']\n",
    "                currMax = lastValues[len(lastValues)-1]['max']\n",
    "                prevMin = lastValues[len(lastValues)-2]['min']\n",
    "                prevMax = lastValues[len(lastValues)-2]['max']\n",
    "                if (currMin > prevMax):\n",
    "                    jump = \"definite up\"\n",
    "                if (currMax < prevMin):\n",
    "                    jump = \"definite down\"\n",
    "\n",
    "        if (jump != \"\"):\n",
    "            print(f\"Found {jump} jump at commit {row['commit']} for type {row['type']}.\")\n",
    "\n",
    "        # Trend detection\n",
    "        trend = \"\"\n",
    "        #Clear values if there is a definite jump\n",
    "        if (jump.startswith(\"definite\")):\n",
    "            lastValues = lastValues[-1:]\n",
    "\n",
    "        if (len(lastValues) > 2):\n",
    "            currVal = lastValues[len(lastValues)-1]['med']\n",
    "            sumOfPrevVals = 0\n",
    "            for val in lastValues[:-1]:\n",
    "                sumOfPrevVals += val['med']\n",
    "            diff = currVal - (sumOfPrevVals / (len(lastValues)-1))\n",
    "            #print(f\"diff is {diff}. {sumOfPrevVals / slidingAvg} -> {currVal}\")\n",
    "            if (diff > trendThreshold):\n",
    "                trend = \"potential up\"\n",
    "            if ((-1 * diff) > trendThreshold):\n",
    "                trend = \"potential down\"\n",
    "            if (trend != \"\"):\n",
    "                currMin = lastValues[len(lastValues)-1]['min']\n",
    "                currMax = lastValues[len(lastValues)-1]['max']\n",
    "                for val in lastValues[:-1]:\n",
    "                    prevMin = val['min']\n",
    "                    prevMax = val['max']\n",
    "                    if (currMin > prevMax):\n",
    "                        trend = \"definite up\"\n",
    "                    if (currMax < prevMin):\n",
    "                        trend = \"definite down\"\n",
    "\n",
    "\n",
    "        if (trend != \"\"):\n",
    "            print(f\"Found {trend} trend at commit {row['commit']} for type {row['type']}.\")\n",
    "\n",
    "        # Remove first element\n",
    "        if (len(lastValues) > slidingAvg):\n",
    "            lastValues.pop(0)\n",
    "\n",
    "        rows.append({\n",
    "            \"commit\":row[\"commit\"],\n",
    "            \"type\": row[\"type\"],\n",
    "            \"min\": row[\"min\"],\n",
    "            \"med\": row[\"med\"],\n",
    "            \"max\": row[\"max\"],\n",
    "            \"jump\": jump,\n",
    "            \"trend\": trend\n",
    "        })\n",
    "\n",
    "print(\"Done.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to file ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Save to file ...\")\n",
    "df_result = pd.DataFrame(rows)\n",
    "df_result.sort_values(by=[\"commit\"], inplace=True)\n",
    "df_result.to_csv(str(resultfile))\n",
    "print(\"Done.\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}