{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "rng = default_rng()\n",
    "\n",
    "\n",
    "numberOfSamples = 10000\n",
    "CIsmall = 1\n",
    "CImed = 5\n",
    "CIlarge = 10\n",
    "folder = \"../../results_all/app_AA-test_influxdb/\"\n",
    "filename = \"../../results_all/app_AA-test_influxdb/app_AA-test_influxdb.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "print(\"start...\")\n",
    "df_latencies = pd.read_csv(filename)\n",
    "print(\"done.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running analysis for type group-by queries...\n",
      "    Found median performance change (0.09106802734279995).\n",
      "i is 0\n",
      "i is 1000\n",
      "i is 2000\n",
      "i is 3000\n",
      "i is 4000\n",
      "i is 5000\n",
      "i is 6000\n",
      "i is 7000\n",
      "i is 8000\n",
      "i is 9000\n",
      "    Bootstrapping done (10000 elements in R).\n",
      "    Found conf. intervals ([-1.2935316574425815, 1.3307707008986203],[-0.9215379831507553, 0.9454296308481824],[-0.7651213336614893, 0.7680668177489025]).\n",
      "Running analysis for type inserts...\n",
      "    Found median performance change (-0.817209054571566).\n",
      "i is 0\n",
      "i is 1000\n",
      "i is 2000\n",
      "i is 3000\n",
      "i is 4000\n",
      "i is 5000\n",
      "i is 6000\n",
      "i is 7000\n",
      "i is 8000\n",
      "i is 9000\n",
      "    Bootstrapping done (10000 elements in R).\n",
      "    Found conf. intervals ([-0.5637702047301185, 0.5682462000334843],[-0.43302436793090093, 0.4457082727262529],[-0.3660247858768617, 0.3758903405880698]).\n",
      "Running analysis for type simple queries...\n",
      "    Found median performance change (0.4696589666363993).\n",
      "i is 0\n",
      "i is 1000\n",
      "i is 2000\n",
      "i is 3000\n",
      "i is 4000\n",
      "i is 5000\n",
      "i is 6000\n",
      "i is 7000\n",
      "i is 8000\n",
      "i is 9000\n",
      "    Bootstrapping done (10000 elements in R).\n",
      "    Found conf. intervals ([-1.6236182182827408, 1.616701338788329],[-1.2463983207007479, 1.233267064801713],[-1.0284642187974424, 0.9983951422671389]).\n"
     ]
    }
   ],
   "source": [
    "def resample(perfRuntimes1: pd.DataFrame,\n",
    "            perfRuntimes2: pd.DataFrame,\n",
    "            instanceRuns: np.ndarray,\n",
    "            samples: int,\n",
    "            numberOfSamples: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "        Resamples performances using hierarchical bootstrapping for building confindence intervals\n",
    "\n",
    "        Builds a tensor of random indices of a form numberOfSamples * instanceRunsNumber * suiteRunsNumber * numberOfIterations.\n",
    "        Then uses these indices to choose from a performance runtimes tensor with a form instanceRunsNumber * suiteRunsNumber * numberOfIterations.\n",
    "        Finally, reshapes resulting tensor to a matrix of form numberOfSamples * ( instanceRunsNumber * suiteRunsNumber * numberOfIterations)\n",
    "        and calculates performance differences between medians.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        perfRuntimes1 : performance runtimes of the first version.\n",
    "        perfRuntimes2 : performance runtimes of the second version.\n",
    "        instanceRuns : array of instanceRun numbers\n",
    "        samples : number of microbenchmark iterations\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            array of performance differences with a shape numberOfSample * 1.\n",
    "\n",
    "        \"\"\"\n",
    "    instanceRunsNumber = instanceRuns.shape[0]\n",
    "\n",
    "    allRuntimes1 = np.ndarray((instanceRunsNumber, samples))\n",
    "    allRuntimes2 = np.ndarray((instanceRunsNumber, samples))\n",
    "\n",
    "\n",
    "    for instanceRun in instanceRuns:\n",
    "        allRuntimes1[instanceRun - 1]= perfRuntimes1.loc[(perfRuntimes1['run'] == instanceRun),\n",
    "                                                'latency (ms)'].to_numpy()\n",
    "        allRuntimes2[instanceRun - 1]= perfRuntimes2.loc[(perfRuntimes2['run'] == instanceRun),\n",
    "                                                'latency (ms)'].to_numpy()\n",
    "\n",
    "    medians = []\n",
    "    for i in range(numberOfSamples):\n",
    "        if (i % 1000 == 0):\n",
    "            print(f\"i is {i}\")\n",
    "        #Generate Random Arrays\n",
    "        currentInstanceRun = rng.choice(instanceRuns, size=(instanceRunsNumber)) - 1\n",
    "        currentRuntimes1 = rng.integers(samples, size=(samples, instanceRunsNumber))\n",
    "        currentRuntimes2 = rng.integers(samples, size=(samples, instanceRunsNumber))\n",
    "        #Bulk selection\n",
    "        tmp1 = allRuntimes1[currentInstanceRun, currentRuntimes1]\n",
    "        tmp1 = tmp1.reshape((instanceRunsNumber * samples))\n",
    "\n",
    "        tmp2 = allRuntimes2[currentInstanceRun, currentRuntimes2]\n",
    "        tmp2 = tmp2.reshape((instanceRunsNumber * samples))\n",
    "\n",
    "        # Get median for both lists\n",
    "        med1 = np.median(tmp1, axis=0)\n",
    "        med2 = np.median(tmp2, axis=0)\n",
    "        medians.append(med2/med1)\n",
    "\n",
    "    return medians\n",
    "\n",
    "\n",
    "# For each type\n",
    "for type in df_latencies.type.unique():\n",
    "    print(f\"Running analysis for type {type}...\")\n",
    "\n",
    "    benchmarkMeasurements = df_latencies.loc[(df_latencies['type'].str.startswith(type, na=False))]\n",
    "    instanceRuns = benchmarkMeasurements.run.unique()\n",
    "    numberOfInstanceRuns = len(instanceRuns)\n",
    "    results = []\n",
    "\n",
    "    #Find median perf. change\n",
    "    perfRuntimes1 = benchmarkMeasurements.loc[(benchmarkMeasurements['version'] == \"base\")]\n",
    "    perfRuntimes2 = benchmarkMeasurements.loc[(benchmarkMeasurements['version'] == \"variation\")]\n",
    "\n",
    "    elements1 = perfRuntimes1['latency (ms)'].shape[0]\n",
    "    elements2 = perfRuntimes2['latency (ms)'].shape[0]\n",
    "    perf1 = perfRuntimes1['latency (ms)'].median()\n",
    "    perf2 = perfRuntimes2['latency (ms)'].median()\n",
    "    # Compare both (e.g., 10ms in ver1 and 12ms in ver2 => 12/10 = 1.2 (>1 -> regression)\n",
    "    perfChange = ((perf2/perf1) - 1) * 100\n",
    "\n",
    "    print(f\"    Found median performance change ({perfChange}).\")\n",
    "\n",
    "    # Run Bootstrapping\n",
    "    # R stores the 10.000 median values\n",
    "    R = resample(perfRuntimes1=perfRuntimes1,\n",
    "            perfRuntimes2=perfRuntimes2,\n",
    "            instanceRuns=instanceRuns,\n",
    "            samples=int(len(perfRuntimes1) / numberOfInstanceRuns),\n",
    "            numberOfSamples=numberOfSamples)\n",
    "\n",
    "    print(f\"    Bootstrapping done ({len(R)} elements in R).\")\n",
    "\n",
    "    # Find conf. intervals\n",
    "    R.sort()\n",
    "\n",
    "    small = int((numberOfSamples * CIsmall) / 100 / 2)\n",
    "    if small == 0:\n",
    "        small  = 1\n",
    "    medium = int((numberOfSamples * CImed) / 100 / 2)\n",
    "    large = int((numberOfSamples * CIlarge) / 100 / 2)\n",
    "\n",
    "    minSmall = R[small-1]\n",
    "    minSmall = (minSmall - 1) * 100\n",
    "    maxSmall = R[numberOfSamples-small-1]\n",
    "    maxSmall = (maxSmall - 1) * 100\n",
    "\n",
    "    minMedium = R[medium-1]\n",
    "    minMedium = (minMedium - 1) * 100\n",
    "    maxMedium = R[numberOfSamples-medium-1]\n",
    "    maxMedium = (maxMedium - 1) * 100\n",
    "\n",
    "    minLarge = R[large-1]\n",
    "    minLarge = (minLarge - 1) * 100\n",
    "    maxLarge = R[numberOfSamples-large-1]\n",
    "    maxLarge = (maxLarge - 1) * 100\n",
    "\n",
    "    print(f\"    Found conf. intervals ([{minSmall}, {maxSmall}],[{minMedium}, {maxMedium}],[{minLarge}, {maxLarge}]).\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}